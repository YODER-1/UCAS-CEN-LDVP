{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f22c7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from collections import Counter\n",
    "import re\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import os\n",
    "excel_file_path = '2018科研人员在线学习数据集.xlsx'\n",
    "all_data_df = pd.read_excel(excel_file_path, sheet_name='所有选学数据')\n",
    "selected_only_df = pd.read_excel(excel_file_path, sheet_name='仅选学未学')\n",
    "selected_and_learned_df = pd.read_excel(excel_file_path, sheet_name='选学且学习')\n",
    "print(\"Data loaded successfully!\")\n",
    "output_dir = 'data'\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ba81be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pandas import Timestamp, Interval\n",
    "class CustomJSONEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, Timestamp):\n",
    "            return obj.strftime('%Y-%m-%d')\n",
    "        elif isinstance(obj, Interval):\n",
    "            return str(obj)\n",
    "        elif isinstance(obj, (np.integer, int)):\n",
    "                return int(obj)\n",
    "        elif isinstance(obj, (np.floating, float)):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, (np.ndarray, list)):\n",
    "            return obj.tolist()\n",
    "        return super().default(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ffa46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_and_transform_df(df):\n",
    "    df.columns = df.columns.str.strip().str.replace('（', '(').str.replace('）', ')').str.replace(' ', '')\n",
    "    if '学习日期' in df.columns:\n",
    "        df['学习日期'] = pd.to_datetime(df['学习日期'], errors='coerce')\n",
    "    if '学习时间' in df.columns:\n",
    "        df['学习时间_td'] = df['学习时间'].astype(str).apply(lambda x: pd.to_timedelta(x + ':00') if x.count(':') == 1 else pd.to_timedelta(x, errors='coerce'))\n",
    "    if '年龄(岁)' in df.columns:\n",
    "        df['年龄(岁)'] = pd.to_numeric(df['年龄(岁)'], errors='coerce').astype('Int64') \n",
    "    if '工作年限(年)' in df.columns:\n",
    "        df['工作年限(年)'] = pd.to_numeric(df['工作年限(年)'], errors='coerce').astype('Int64')\n",
    "    if '课程时长(小时)' in df.columns:\n",
    "        df['课程时长(小时)'] = pd.to_numeric(df['课程时长(小时)'], errors='coerce')\n",
    "    if '学习时长(小时)' in df.columns:\n",
    "        df['学习时长(小时)'] = pd.to_numeric(df['学习时长(小时)'], errors='coerce')\n",
    "    df['职级'] = df['职级'].replace('中级级', '中级')\n",
    "    for col in ['年龄(岁)', '工作年限(年)', '课程时长(小时)', '学习时长(小时)']:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].fillna(0)\n",
    "    for col in ['性别', '职级', '课程名称']:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].fillna('未知')\n",
    "    return df\n",
    "\n",
    "all_data_df = clean_and_transform_df(all_data_df)\n",
    "selected_only_df = clean_and_transform_df(selected_only_df)\n",
    "selected_and_learned_df = clean_and_transform_df(selected_and_learned_df)\n",
    "\n",
    "print(\"\\n'所有选学数据'\")\n",
    "print(all_data_df.head())\n",
    "print(\"\\n'选学且学习'\")\n",
    "print(selected_and_learned_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0e3e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 总选课人数\n",
    "total_selected_users = all_data_df['人员ID'].nunique()\n",
    "total_course = all_data_df['课程ID'].nunique()\n",
    "# 实际学习人数\n",
    "actual_learning_users = selected_and_learned_df['人员ID'].nunique()\n",
    "# 选课未学习人数\n",
    "selected_not_learned_users = actual_learning_users - selected_only_df['人员ID'].nunique()\n",
    "# 学习转化率\n",
    "learning_conversion_rate = actual_learning_users / total_selected_users if total_selected_users > 0 else 0\n",
    "# 总选课数量\n",
    "total_selected_courses_count = len(all_data_df)\n",
    "# 总学习时长\n",
    "total_learning_duration_hours = selected_and_learned_df['学习时长(小时)'].sum()\n",
    "# 人均选课数量\n",
    "avg_courses_per_total_learner = total_selected_courses_count / total_selected_users if total_selected_users > 0 else 0\n",
    "# 人均学习时长\n",
    "avg_learning_duration_per_actual_learner = total_learning_duration_hours / actual_learning_users if actual_learning_users > 0 else 0\n",
    "overall_participation_results = {\n",
    "    \"total_course\": total_course,\n",
    "    \"total_selected_users\": total_selected_users,\n",
    "    \"actual_learning_users\": actual_learning_users,\n",
    "    \"selected_not_learned_users\": selected_not_learned_users,\n",
    "    \"learning_conversion_rate\": round(learning_conversion_rate, 4),\n",
    "    \"total_selected_courses_count\": total_selected_courses_count,\n",
    "    \"total_learning_duration_hours\": round(total_learning_duration_hours, 2),\n",
    "    \"avg_courses_per_total_learner\": round(avg_courses_per_total_learner, 2),\n",
    "    \"avg_learning_duration_per_actual_learner\": round(avg_learning_duration_per_actual_learner, 2)\n",
    "}\n",
    "\n",
    "with open(os.path.join(output_dir, 'overall_participation.json'), 'w', encoding='utf-8') as f:\n",
    "    json.dump(overall_participation_results, f, indent=4, ensure_ascii=False)\n",
    "print(json.dumps(overall_participation_results, indent=4, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc92fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "demographic_analysis_results = {}\n",
    "\n",
    "temp_learned_df_for_demog = selected_and_learned_df.copy()\n",
    "temp_learned_df_for_demog['课程时长(小时)'] = temp_learned_df_for_demog['课程时长(小时)'].replace(0, pd.NA)\n",
    "temp_learned_df_for_demog['学习完成度'] = temp_learned_df_for_demog['学习时长(小时)'] / temp_learned_df_for_demog['课程时长(小时)']\n",
    "temp_learned_df_for_demog['学习完成度'] = temp_learned_df_for_demog['学习完成度'].fillna(0).replace([float('inf'), float('-inf')], 0)\n",
    "\n",
    "\n",
    "def analyze_demographic_group(df_all, df_learned, demographic_col):\n",
    "    results = {}\n",
    "    \n",
    "    if demographic_col not in df_all.columns or demographic_col not in df_learned.columns:\n",
    "        print(f\"Warning: Demographic column '{demographic_col}' not found.\")\n",
    "        return results\n",
    "\n",
    "    grouped_all = df_all.groupby(demographic_col)['人员ID'].nunique().rename('总选课人数')\n",
    "    grouped_learned_users = df_learned.groupby(demographic_col)['人员ID'].nunique().rename('实际学习人数')\n",
    "    \n",
    "    merged_df = pd.merge(grouped_all, grouped_learned_users, left_index=True, right_index=True, how='left').fillna(0)\n",
    "    merged_df['群体学习参与率'] = merged_df['实际学习人数'] / merged_df['总选课人数']\n",
    "    merged_df['群体学习参与率'] = merged_df['群体学习参与率'].fillna(0).round(4)\n",
    "\n",
    "    grouped_learned = df_learned.groupby(demographic_col)\n",
    "    \n",
    "    avg_courses_per_person = grouped_learned.apply(lambda x: x.groupby('人员ID')['课程ID'].nunique().mean() if len(x) > 0 else 0).rename('人均学习课程数')\n",
    "    avg_study_duration_per_person = grouped_learned.apply(lambda x: x['学习时长(小时)'].sum() / x['人员ID'].nunique() if x['人员ID'].nunique() > 0 else 0).rename('人均学习时长')\n",
    "    avg_completion_rate = grouped_learned['学习完成度'].mean().rename('学习完成度均值')\n",
    "    course_coverage = grouped_learned.apply(lambda x: x['课程ID'].nunique() / x['人员ID'].nunique() if x['人员ID'].nunique() > 0 else 0).rename('课程覆盖度')\n",
    "\n",
    "    final_demographic_df = pd.concat([merged_df, avg_courses_per_person, avg_study_duration_per_person, avg_completion_rate, course_coverage], axis=1).fillna(0)\n",
    "    \n",
    "    return final_demographic_df.reset_index().to_dict(orient='records')\n",
    "\n",
    "demographic_analysis_results['gender_analysis'] = analyze_demographic_group(all_data_df, temp_learned_df_for_demog, '性别')\n",
    "demographic_analysis_results['age_analysis'] = analyze_demographic_group(all_data_df, temp_learned_df_for_demog, '年龄(岁)')\n",
    "demographic_analysis_results['rank_analysis'] = analyze_demographic_group(all_data_df, temp_learned_df_for_demog, '职级')\n",
    "\n",
    "with open(os.path.join(output_dir, 'demographic_analysis.json'), 'w', encoding='utf-8') as f:\n",
    "    json.dump(demographic_analysis_results, f, indent=4, ensure_ascii=False)\n",
    "print(json.dumps(demographic_analysis_results, indent=4, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed9bc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "course_preference_results = {}\n",
    "\n",
    "# 课程学习人数：每门课程在“选学且学习”中的唯一人员ID数\n",
    "course_learners = selected_and_learned_df.groupby('课程名称')['人员ID'].nunique().sort_values(ascending=False)\n",
    "course_preference_results['course_learners'] = course_learners.to_dict()\n",
    "\n",
    "temp_learned_df_for_course = selected_and_learned_df.copy()\n",
    "temp_learned_df_for_course['课程时长(小时)'] = temp_learned_df_for_course['课程时长(小时)'].replace(0, pd.NA)\n",
    "temp_learned_df_for_course['学习完成度'] = temp_learned_df_for_course['学习时长(小时)'] / temp_learned_df_for_course['课程时长(小时)']\n",
    "temp_learned_df_for_course['学习完成度'] = temp_learned_df_for_course['学习完成度'].fillna(0).replace([float('inf'), float('-inf')], 0)\n",
    "\n",
    "# 课程完成度均值\n",
    "course_completion_avg = temp_learned_df_for_course.groupby('课程名称')['学习完成度'].mean().sort_values(ascending=False)\n",
    "course_preference_results['course_completion_avg'] = course_completion_avg.round(4).to_dict()\n",
    "\n",
    "# 高完成课程占比\n",
    "high_completion_courses = temp_learned_df_for_course[temp_learned_df_for_course['学习完成度'] > 0.8]['课程名称'].nunique()\n",
    "total_unique_learned_courses = temp_learned_df_for_course['课程名称'].nunique()\n",
    "course_preference_results['high_completion_course_ratio'] = round(high_completion_courses / total_unique_learned_courses, 4) if total_unique_learned_courses > 0 else 0\n",
    "\n",
    "# 重复学习率\n",
    "course_user_counts = selected_and_learned_df.groupby(['人员ID', '课程ID']).size()\n",
    "repeated_studies = course_user_counts[course_user_counts > 1]\n",
    "num_repeated_records = repeated_studies.apply(lambda x: x - 1).sum()\n",
    "total_study_records = len(selected_and_learned_df)\n",
    "course_preference_results['repeated_learning_rate'] = round(num_repeated_records / total_study_records, 4) if total_study_records > 0 else 0\n",
    "def get_word_frequencies(df, column_name):\n",
    "    text = ' '.join(df[column_name].astype(str).tolist())\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    words = [word for word in words if len(word) > 1] # Filter short words\n",
    "    return Counter(words).most_common(50)\n",
    "course_preference_results['selected_only_course_word_cloud'] = get_word_frequencies(selected_only_df, '课程名称')\n",
    "course_preference_results['selected_and_learned_course_word_cloud'] = get_word_frequencies(selected_and_learned_df, '课程名称')\n",
    "\n",
    "# Top 10热门课程\n",
    "top_10_popular_courses = course_learners.head(10)\n",
    "course_preference_results['top_10_popular_courses'] = top_10_popular_courses.to_dict()\n",
    "\n",
    "scatter_df = temp_learned_df_for_course[['课程时长(小时)', '学习时长(小时)']].dropna()\n",
    "scatter_df = scatter_df[(scatter_df['课程时长(小时)'] > 0) & (scatter_df['学习时长(小时)'] > 0)]\n",
    "course_preference_results['course_duration_scatter_data'] = scatter_df.to_dict(orient='records')\n",
    "\n",
    "completion_bins = [i/10 for i in range(11)]\n",
    "completion_distribution = temp_learned_df_for_course['学习完成度'].value_counts(bins=completion_bins, normalize=True).sort_index()\n",
    "completion_distribution.index = completion_distribution.index.astype(str)\n",
    "course_preference_results['completion_distribution'] = completion_distribution.round(4).to_dict()\n",
    "\n",
    "unique_learned_courses = selected_and_learned_df['课程ID'].nunique()\n",
    "unique_selected_courses = all_data_df['课程ID'].nunique() \n",
    "course_preference_results['course_learning_conversion_rate'] = round(unique_learned_courses / unique_selected_courses, 4) if unique_selected_courses > 0 else 0\n",
    "\n",
    "with open(os.path.join(output_dir, 'course_preferences.json'), 'w', encoding='utf-8') as f:\n",
    "    json.dump(course_preference_results, f, indent=4, ensure_ascii=False,cls=CustomJSONEncoder)\n",
    "\n",
    "print(json.dumps(course_preference_results, indent=4, ensure_ascii=False,cls=CustomJSONEncoder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5452ee45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import jieba.analyse\n",
    "from collections import Counter\n",
    "import re\n",
    "course_preference_results_ciyun={}\n",
    "def process_word_cloud_data(df, column_name):\n",
    "\n",
    "    stopwords = {\n",
    "}\n",
    "    \n",
    "    custom_words = {\n",
    "        'Python', 'Java', 'C++', 'R语言', '机器学习', '深度学习', '人工智能',\n",
    "        '数据分析', '数据挖掘', '数据可视化', '统计分析', '回归分析'\n",
    "    }\n",
    "    for word in custom_words:\n",
    "        jieba.add_word(word)\n",
    "    \n",
    "    text = ' '.join(df[column_name].astype(str).tolist())\n",
    "    \n",
    "    words = jieba.cut(text)\n",
    "    \n",
    "    valid_words = []\n",
    "    for word in words:\n",
    "        if (word not in stopwords and  \n",
    "            len(word.strip()) > 1 and \n",
    "            not word.isdigit() and    \n",
    "            not re.match(r'^[0-9a-zA-Z.]+$', word)): \n",
    "            valid_words.append(word)\n",
    "    \n",
    "    word_counts = Counter(valid_words)\n",
    "    \n",
    "    keywords = jieba.analyse.extract_tags(\n",
    "        ' '.join(valid_words),\n",
    "        topK=50,  \n",
    "        withWeight=True,  \n",
    "        allowPOS=('n', 'vn', 'v')\n",
    "    )\n",
    "    \n",
    "    word_cloud_data = []\n",
    "    for keyword, weight in keywords:\n",
    "        if keyword in word_counts:\n",
    "            word_cloud_data.append({\n",
    "                \"text\": keyword,\n",
    "                \"size\": int(weight * 1000),  \n",
    "                \"weight\": float(f\"{weight:.4f}\"),  \n",
    "                \"frequency\": word_counts[keyword]  \n",
    "            })\n",
    "    \n",
    "    return word_cloud_data\n",
    "\n",
    "def update_course_preference_results(course_preference_results, selected_only_df, selected_and_learned_df):\n",
    "\n",
    "    selected_only_cloud = process_word_cloud_data(selected_only_df, '课程名称')\n",
    "    course_preference_results['selected_only_word_cloud'] = selected_only_cloud\n",
    "    \n",
    "    learned_cloud = process_word_cloud_data(selected_and_learned_df, '课程名称')\n",
    "    course_preference_results['learned_word_cloud'] = learned_cloud\n",
    "    \n",
    "    return course_preference_results\n",
    "\n",
    "course_preference_results_ciyun = update_course_preference_results(\n",
    "    course_preference_results_ciyun,\n",
    "    selected_only_df,\n",
    "    selected_and_learned_df\n",
    ")\n",
    "\n",
    "with open(os.path.join(output_dir, 'course_preferences_ciyun.json'), 'w', encoding='utf-8') as f:\n",
    "    json.dump(course_preference_results_ciyun, f, indent=4, ensure_ascii=False, cls=CustomJSONEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ae3cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_behavior_results = {}\n",
    "\n",
    "temp_learned_df_for_time = selected_and_learned_df.copy()\n",
    "temp_learned_df_for_time.dropna(subset=['学习日期', '学习时间_td'], inplace=True)\n",
    "temp_learned_df_for_time['学习小时'] = temp_learned_df_for_time['学习时间_td'].dt.components.hours\n",
    "\n",
    "# 学习活跃时间段分布\n",
    "bins = [0, 6, 9, 12, 18, 24]\n",
    "labels = ['深夜(0-6点)', '早晨(6-9点)', '上午(9-12点)', '下午(12-18点)', '晚上(18-24点)']\n",
    "temp_learned_df_for_time['时间段'] = pd.cut(temp_learned_df_for_time['学习小时'], bins=bins, labels=labels, right=False, include_lowest=True)\n",
    "\n",
    "time_period_distribution = temp_learned_df_for_time['时间段'].value_counts(normalize=True).sort_index()\n",
    "time_behavior_results['time_period_distribution'] = time_period_distribution.round(4).to_dict()\n",
    "\n",
    "# 日活学习人数 \n",
    "daily_active_users = temp_learned_df_for_time.groupby('学习日期')['人员ID'].nunique()\n",
    "time_behavior_results['daily_active_users'] = daily_active_users.reset_index().rename(columns={'学习日期': 'date', '人员ID': 'active_users'}).to_dict(orient='records')\n",
    "\n",
    "\n",
    "# 时间集中度: 统计每人所有学习记录的时间段占比，计算最高占比即为该人员的时间偏好集中度\n",
    "user_time_preference = {}\n",
    "for user_id, group in temp_learned_df_for_time.groupby('人员ID'):\n",
    "    period_counts = group['时间段'].value_counts(normalize=True)\n",
    "    if not period_counts.empty:\n",
    "        user_time_preference[user_id] = period_counts.max()\n",
    "    else:\n",
    "        user_time_preference[user_id] = 0\n",
    "time_behavior_results['user_time_concentration_avg'] = round(np.mean(list(user_time_preference.values())), 4)\n",
    "time_behavior_results['user_time_concentration_raw'] = {str(k): round(v, 4) for k, v in user_time_preference.items()}\n",
    "\n",
    "# 学习节奏稳定性\n",
    "temp_learned_df_for_time['学习完整时间'] = temp_learned_df_for_time['学习日期'] + temp_learned_df_for_time['学习时间_td']\n",
    "\n",
    "user_study_rhythm_stability = {}\n",
    "for user_id, group in temp_learned_df_for_time.groupby('人员ID'):\n",
    "    if len(group) > 1:\n",
    "        timestamps = group['学习完整时间'].apply(lambda x: x.timestamp()).sort_values()\n",
    "        user_study_rhythm_stability[user_id] = timestamps.std()\n",
    "    else:\n",
    "        user_study_rhythm_stability[user_id] = 0\n",
    "time_behavior_results['user_study_rhythm_stability_avg'] = round(np.mean(list(user_study_rhythm_stability.values())), 2)\n",
    "time_behavior_results['user_study_rhythm_stability_raw'] = {str(k): round(v, 2) for k, v in user_study_rhythm_stability.items()}\n",
    "\n",
    "temp_learned_df_for_time['weekday'] = temp_learned_df_for_time['学习日期'].dt.dayofweek\n",
    "temp_learned_df_for_time['hour'] = temp_learned_df_for_time['学习小时']\n",
    "\n",
    "calendar_heatmap_data = temp_learned_df_for_time.groupby(['weekday', 'hour']).size().unstack(fill_value=0)\n",
    "heatmap_list = []\n",
    "for weekday in calendar_heatmap_data.index:\n",
    "    for hour in calendar_heatmap_data.columns:\n",
    "        heatmap_list.append({\n",
    "            \"weekday\": int(weekday),\n",
    "            \"hour\": int(hour),\n",
    "            \"count\": int(calendar_heatmap_data.loc[weekday, hour])\n",
    "        })\n",
    "time_behavior_results['calendar_heatmap_data'] = heatmap_list\n",
    "\n",
    "with open(os.path.join(output_dir, 'time_behavior.json'), 'w', encoding='utf-8') as f:\n",
    "    json.dump(time_behavior_results, f, indent=4, ensure_ascii=False,cls=CustomJSONEncoder)\n",
    "print(json.dumps(time_behavior_results, indent=4, ensure_ascii=False,cls=CustomJSONEncoder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03087d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_efficiency_results = {}\n",
    "\n",
    "temp_learned_df_for_quality = selected_and_learned_df.copy()\n",
    "temp_learned_df_for_quality['课程时长(小时)'] = temp_learned_df_for_quality['课程时长(小时)'].replace(0, pd.NA)\n",
    "temp_learned_df_for_quality['学习完成度'] = temp_learned_df_for_quality['学习时长(小时)'] / temp_learned_df_for_quality['课程时长(小时)']\n",
    "temp_learned_df_for_quality['学习完成度'] = temp_learned_df_for_quality['学习完成度'].fillna(0).replace([float('inf'), float('-inf')], 0)\n",
    "\n",
    "# '学习完整时间'\n",
    "temp_learned_df_for_quality['学习完整时间'] = temp_learned_df_for_quality['学习日期'] + temp_learned_df_for_quality['学习时间_td']\n",
    "temp_learned_df_for_quality.dropna(subset=['学习完成度', '学习完整时间'], inplace=True)\n",
    "\n",
    "# 平均完成度 = 学习时长 ÷ 课程时长\n",
    "quality_efficiency_results['average_completion_rate'] = round(temp_learned_df_for_quality['学习完成度'].mean(), 4)\n",
    "\n",
    "# 高完成记录占比：完成度 >80% 的记录数 ÷ 总学习记录数\n",
    "high_completion_records = len(temp_learned_df_for_quality[temp_learned_df_for_quality['学习完成度'] > 0.8])\n",
    "total_records = len(temp_learned_df_for_quality)\n",
    "quality_efficiency_results['high_completion_record_ratio'] = round(high_completion_records / total_records, 4) if total_records > 0 else 0\n",
    "\n",
    "# 放弃率：完成度 <20% 的记录占比\n",
    "abandonment_records = len(temp_learned_df_for_quality[temp_learned_df_for_quality['学习完成度'] < 0.2])\n",
    "quality_efficiency_results['abandonment_rate'] = round(abandonment_records / total_records, 4) if total_records > 0 else 0\n",
    "\n",
    "# 平均每次学习时长：所有学习时长之和 ÷ 记录总数\n",
    "quality_efficiency_results['average_duration_per_study_session'] = round(temp_learned_df_for_quality['学习时长(小时)'].mean(), 4)\n",
    "\n",
    "# 平均学习间隔：按每人学习时间排序，计算相邻两次的平均时间间隔。\n",
    "user_avg_intervals = {}\n",
    "for user_id, group in temp_learned_df_for_quality.groupby('人员ID'):\n",
    "    if len(group) > 1:\n",
    "        sorted_times = group['学习完整时间'].sort_values()\n",
    "        intervals = sorted_times.diff().dropna().dt.total_seconds() / (60 * 60)\n",
    "        if not intervals.empty:\n",
    "            user_avg_intervals[user_id] = intervals.mean()\n",
    "        else:\n",
    "            user_avg_intervals[user_id] = 0\n",
    "    else:\n",
    "        user_avg_intervals[user_id] = 0\n",
    "\n",
    "quality_efficiency_results['average_learning_interval_hours'] = round(np.mean(list(user_avg_intervals.values())), 2)\n",
    "quality_efficiency_results['user_learning_intervals_raw'] = {str(k): round(v, 2) for k,v in user_avg_intervals.items()}\n",
    "\n",
    "completion_bins = [i/10 for i in range(11)]\n",
    "completion_counts, _ = np.histogram(temp_learned_df_for_quality['学习完成度'].dropna(), bins=completion_bins)\n",
    "quality_efficiency_results['completion_histogram'] = {f\"{completion_bins[i]}-{completion_bins[i+1]}\": int(completion_counts[i]) for i in range(len(completion_counts))}\n",
    "\n",
    "high_completion_group = temp_learned_df_for_quality[temp_learned_df_for_quality['学习完成度'] > 0.8]\n",
    "low_completion_group = temp_learned_df_for_quality[temp_learned_df_for_quality['学习完成度'] < 0.2]\n",
    "\n",
    "box_plot_data = {\n",
    "    'high_completion_group': {\n",
    "        'age': high_completion_group['年龄(岁)'].dropna().tolist(),\n",
    "        'work_experience': high_completion_group['工作年限(年)'].dropna().tolist(),\n",
    "        'study_duration': high_completion_group['学习时长(小时)'].dropna().tolist()\n",
    "    },\n",
    "    'low_completion_group': {\n",
    "        'age': low_completion_group['年龄(岁)'].dropna().tolist(),\n",
    "        'work_experience': low_completion_group['工作年限(年)'].dropna().tolist(),\n",
    "        'study_duration': low_completion_group['学习时长(小时)'].dropna().tolist()\n",
    "    }\n",
    "}\n",
    "quality_efficiency_results['box_plot_data'] = box_plot_data\n",
    "\n",
    "scatter_df = temp_learned_df_for_quality[['学习完成度', '课程时长(小时)']].dropna()\n",
    "scatter_df = scatter_df[scatter_df['课程时长(小时)'] > 0]\n",
    "quality_efficiency_results['completion_vs_course_duration_scatter'] = scatter_df.to_dict(orient='records')\n",
    "\n",
    "\n",
    "with open(os.path.join(output_dir, 'quality_efficiency.json'), 'w', encoding='utf-8') as f:\n",
    "    json.dump(quality_efficiency_results, f, indent=4, ensure_ascii=False,cls=CustomJSONEncoder)\n",
    "print(json.dumps(quality_efficiency_results, indent=4, ensure_ascii=False,cls=CustomJSONEncoder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6cf35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_results = {}\n",
    "\n",
    "temp_learned_df_for_clustering = selected_and_learned_df.copy()\n",
    "temp_learned_df_for_clustering['课程时长(小时)'] = temp_learned_df_for_clustering['课程时长(小时)'].replace(0, pd.NA)\n",
    "temp_learned_df_for_clustering['学习完成度'] = temp_learned_df_for_clustering['学习时长(小时)'] / temp_learned_df_for_clustering['课程时长(小时)']\n",
    "temp_learned_df_for_clustering['学习完成度'] = temp_learned_df_for_clustering['学习完成度'].fillna(0).replace([float('inf'), float('-inf')], 0)\n",
    "\n",
    "temp_learned_df_for_clustering['学习完整时间'] = temp_learned_df_for_clustering['学习日期'] + temp_learned_df_for_clustering['学习时间_td']\n",
    "temp_learned_df_for_clustering.dropna(subset=['学习完成度', '学习完整时间'], inplace=True)\n",
    "\n",
    "features_df = pd.DataFrame(index=temp_learned_df_for_clustering['人员ID'].unique())\n",
    "\n",
    "# 学习频率维度: 学习记录数\n",
    "features_df['学习记录数'] = temp_learned_df_for_clustering.groupby('人员ID').size()\n",
    "\n",
    "# 学习投入维度: 总学习时长（小时）, 平均单次学习时长\n",
    "features_df['总学习时长(小时)'] = temp_learned_df_for_clustering.groupby('人员ID')['学习时长(小时)'].sum()\n",
    "features_df['平均单次学习时长'] = temp_learned_df_for_clustering.groupby('人员ID')['学习时长(小时)'].mean()\n",
    "\n",
    "# 学习完成度维度: 平均完成度, 高完成率, 放弃率\n",
    "features_df['平均完成度'] = temp_learned_df_for_clustering.groupby('人员ID')['学习完成度'].mean()\n",
    "high_completion_records_by_user = temp_learned_df_for_clustering[temp_learned_df_for_clustering['学习完成度'] >= 0.8].groupby('人员ID').size()\n",
    "features_df['高完成率'] = high_completion_records_by_user / features_df['学习记录数']\n",
    "features_df['高完成率'] = features_df['高完成率'].fillna(0)\n",
    "abandonment_records_by_user = temp_learned_df_for_clustering[temp_learned_df_for_clustering['学习完成度'] < 0.2].groupby('人员ID').size()\n",
    "features_df['放弃率'] = abandonment_records_by_user / features_df['学习记录数']\n",
    "features_df['放弃率'] = features_df['放弃率'].fillna(0) \n",
    "# 学习节奏与习惯维度: 学习时间标准差, 晚间学习占比\n",
    "user_time_std = {}\n",
    "for user_id, group in temp_learned_df_for_clustering.groupby('人员ID'):\n",
    "    if len(group) > 1:\n",
    "        timestamps = group['学习完整时间'].apply(lambda x: x.timestamp()).sort_values()\n",
    "        user_time_std[user_id] = timestamps.std()\n",
    "    else:\n",
    "        user_time_std[user_id] = 0\n",
    "features_df['学习时间标准差'] = features_df.index.map(user_time_std).fillna(0)\n",
    "\n",
    "temp_learned_df_for_clustering['学习小时'] = temp_learned_df_for_clustering['学习时间_td'].dt.components.hours\n",
    "evening_study_by_user = temp_learned_df_for_clustering[(temp_learned_df_for_clustering['学习小时'] >= 18) & (temp_learned_df_for_clustering['学习小时'] < 24)].groupby('人员ID').size()\n",
    "features_df['晚间学习占比'] = evening_study_by_user / features_df['学习记录数']\n",
    "features_df['晚间学习占比'] = features_df['晚间学习占比'].fillna(0)\n",
    "\n",
    "# 多样性维度: 课程种类数\n",
    "features_df['课程种类数'] = temp_learned_df_for_clustering.groupby('人员ID')['课程ID'].nunique()\n",
    "\n",
    "# 重复学习维度: 重复学习率\n",
    "user_repeat_rate = {}\n",
    "for user_id, group in temp_learned_df_for_clustering.groupby('人员ID'):\n",
    "    if len(group) > 0:\n",
    "        course_counts = group['课程ID'].value_counts()\n",
    "        num_repeated_records_user = course_counts[course_counts > 1].apply(lambda x: x - 1).sum()\n",
    "        user_repeat_rate[user_id] = num_repeated_records_user / len(group)\n",
    "    else:\n",
    "        user_repeat_rate[user_id] = 0\n",
    "features_df['重复学习率'] = features_df.index.map(user_repeat_rate).fillna(0)\n",
    "\n",
    "features_df = features_df.fillna(0)\n",
    "\n",
    "\n",
    "print(features_df.head())\n",
    "\n",
    "def find_optimal_clusters(data, max_k=8):\n",
    "    \"\"\"使用肘部法则和轮廓系数确定最优聚类数\"\"\"\n",
    "    from sklearn.metrics import silhouette_score\n",
    "    \n",
    "    # 标准化数据\n",
    "    scaler_test = StandardScaler()\n",
    "    scaled_data = scaler_test.fit_transform(data)\n",
    "    \n",
    "\n",
    "    k_range = range(2, min(max_k + 1, len(data) // 3))\n",
    "    silhouette_scores = []\n",
    "    inertias = []\n",
    "    \n",
    "    for k in k_range:\n",
    "        kmeans_test = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "        labels = kmeans_test.fit_predict(scaled_data)\n",
    "        \n",
    "        # 计算轮廓系数和簇内平方和\n",
    "        sil_score = silhouette_score(scaled_data, labels)\n",
    "        silhouette_scores.append(sil_score)\n",
    "        inertias.append(kmeans_test.inertia_)\n",
    "        \n",
    "        print(f\"  k={k}: 轮廓系数={sil_score:.3f}, 簇内平方和={kmeans_test.inertia_:.0f}\")\n",
    "    \n",
    "    # 找到轮廓系数最高的k\n",
    "    best_k = k_range[np.argmax(silhouette_scores)]\n",
    "    best_score = max(silhouette_scores)\n",
    "    \n",
    "    print(f\"推荐聚类数: {best_k} (轮廓系数: {best_score:.3f})\")\n",
    "    \n",
    "    return best_k\n",
    "\n",
    "# 自动确定最优聚类数\n",
    "if len(features_df) >= 10:\n",
    "    optimal_k = find_optimal_clusters(features_df.drop(columns=['cluster'], errors='ignore'))\n",
    "    n_clusters = optimal_k\n",
    "    print(f\"使用优化后的聚类数: {n_clusters}\")\n",
    "else:\n",
    "    n_clusters = 5  # 数据量太小时的默认值\n",
    "    print(f\"数据量较小，使用默认聚类数: {n_clusters}\")\n",
    "\n",
    "\n",
    "if not features_df.empty:\n",
    "    scaler = StandardScaler()\n",
    "    scaled_features = scaler.fit_transform(features_df)\n",
    "    scaled_features_df = pd.DataFrame(scaled_features, columns=features_df.columns, index=features_df.index)\n",
    "\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init='auto')\n",
    "    features_df['cluster'] = kmeans.fit_predict(scaled_features)\n",
    "\n",
    "    pca = PCA(n_components=2)\n",
    "    principal_components = pca.fit_transform(scaled_features)\n",
    "    pca_df = pd.DataFrame(data=principal_components, columns=['PC1', 'PC2'], index=features_df.index)\n",
    "    pca_df['cluster'] = features_df['cluster']\n",
    "    feature_columns = features_df.columns[:-1] if 'cluster' in features_df.columns else features_df.columns\n",
    "    cluster_centroids_original_scale = pd.DataFrame(scaler.inverse_transform(kmeans.cluster_centers_), columns=feature_columns)\n",
    "    cluster_centroids_original_scale['cluster'] = range(n_clusters)\n",
    "    \n",
    "    clustering_results = {\n",
    "        \"cluster_assignments\": features_df['cluster'].reset_index().rename(columns={'人员ID': 'person_id', 'cluster': 'cluster'}).to_dict(orient='records'),\n",
    "        \"pca_data\": pca_df.reset_index().rename(columns={'人员ID': 'person_id'}).to_dict(orient='records'),\n",
    "        \"cluster_centroids_original_scale\": cluster_centroids_original_scale.round(4).to_dict(orient='records')\n",
    "    }\n",
    "else:\n",
    "    print(\"No features generated for clustering.\")\n",
    "\n",
    "with open(os.path.join(output_dir, 'clustering_results.json'), 'w', encoding='utf-8') as f:\n",
    "    json.dump(clustering_results, f, indent=4, ensure_ascii=False)\n",
    "print(json.dumps(clustering_results, indent=4, ensure_ascii=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
